{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a161bfb-a15e-4a07-9bb0-688b76f87de3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import nn, ops, Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151fbcbf-b579-4e28-95fa-2e0ab4e47f7a",
   "metadata": {},
   "source": [
    "# GPT-2 Masked Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab3a91-292b-420d-9b61-c85280dd8dee",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 1- Creating queries, keys, and values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22664691-6db2-4d62-a76a-a4a8a6050199",
   "metadata": {},
   "source": [
    "![gpt2-self-attention-3.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d2591f-26c2-4961-bca3-be30c4352aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 10\n",
    "embed_dim = 768\n",
    "\n",
    "x = Tensor(np.random.randn(batch_size, seq_len, embed_dim), mindspore.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d315a4e-5663-404e-b93d-efb1cf354414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/ipykernel/iostream.py:153: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0xfffe7003a940>\n",
      "  self._event_pipes[threading.current_thread()] = event_pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1, 10, 768), (1, 10, 768), (1, 10, 768))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindnlp._legacy.functional import split\n",
    "from mindnlp.transformers.ms_utils import Conv1D\n",
    "\n",
    "c_attn = Conv1D(3 * embed_dim, embed_dim)\n",
    "query, key, value = split(c_attn(x), embed_dim, axis=2)\n",
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7757e-16e4-4ff9-8a63-3e19767588db",
   "metadata": {},
   "source": [
    "![gpt2-self-attention-split-attention-heads-1.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-split-attention-heads-1.png)\n",
    "\n",
    "![gpt2-self-attention-split-attention-heads-2.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-split-attention-heads-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb7ccac-7cfe-401a-ab32-763de70b4669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_heads(tensor, num_heads, attn_head_size):\n",
    "    \"\"\"\n",
    "    Splits hidden_size dim into attn_head_size and num_heads\n",
    "    \"\"\"\n",
    "    new_shape = tensor.shape[:-1] + (num_heads, attn_head_size)\n",
    "    tensor = tensor.view(new_shape)\n",
    "    return ops.transpose(tensor, (0, 2, 1, 3))  # (batch, head, seq_length, head_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72abe0fe-5225-425b-9bda-0723f3fb27cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 12, 10, 64), (1, 12, 10, 64), (1, 12, 10, 64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    }
   ],
   "source": [
    "num_heads = 12\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "query = split_heads(query, num_heads, head_dim)\n",
    "key = split_heads(key, num_heads, head_dim)\n",
    "value = split_heads(value, num_heads, head_dim)\n",
    "\n",
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f65b2-b291-4ad1-b3ea-8e77e6a254d3",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 2- Scoring\n",
    "\n",
    "![gpt2-self-attention-scoring.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-scoring.png)\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-scoring-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f952236-de74-4419-9469-7e78d3b7c3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 10, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\r"
     ]
    }
   ],
   "source": [
    "attn_weights = ops.matmul(query, key.swapaxes(-1, -2))\n",
    "\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d6de9-cdb7-40cd-aed1-e4fe059054b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](https://jalammar.github.io/images/gpt2/transformer-decoder-attention-mask-dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff22248-deff-4962-afae-55772f63f142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 1, 10, 10], dtype=Bool, value=\n",
       "[[[[ True, False, False ... False, False, False],\n",
       "   [ True,  True, False ... False, False, False],\n",
       "   [ True,  True,  True ... False, False, False],\n",
       "   ...\n",
       "   [ True,  True,  True ...  True, False, False],\n",
       "   [ True,  True,  True ...  True,  True, False],\n",
       "   [ True,  True,  True ...  True,  True,  True]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_positions = seq_len\n",
    "\n",
    "bias = Tensor(np.tril(np.ones((max_positions, max_positions))).reshape(\n",
    "              (1, 1, max_positions, max_positions)), mindspore.bool_)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783a2bc-01dd-4496-a018-ac01e643cd89",
   "metadata": {},
   "source": [
    "![](https://jalammar.github.io/images/gpt2/queries-keys-attention-mask.png)\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/transformer-attention-mask.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d957ce17-6df6-4f5e-a262-24ff3a8ce0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\r"
     ]
    }
   ],
   "source": [
    "from mindnlp._legacy.functional import where, softmax\n",
    "\n",
    "attn_weights = attn_weights / ops.sqrt(ops.scalar_to_tensor(value.shape[-1]))\n",
    "query_length, key_length = query.shape[-2], key.shape[-2]\n",
    "causal_mask = bias[:, :, key_length - query_length: key_length, :key_length].bool()\n",
    "mask_value = Tensor(np.finfo(np.float32).min, dtype=attn_weights.dtype)\n",
    "attn_weights = where(causal_mask, attn_weights, mask_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee63bfd-f394-4558-9e9f-e102a2fd283c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4028235e+38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(np.float32).min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2faad14-9a3d-4495-8bcc-d7ac2695e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[10, 10], dtype=Float32, value=\n",
       "[[-4.46166992e-02, -3.40282347e+38, -3.40282347e+38 ... -3.40282347e+38, -3.40282347e+38, -3.40282347e+38],\n",
       " [-3.74755859e-02, -4.25109863e-02, -3.40282347e+38 ... -3.40282347e+38, -3.40282347e+38, -3.40282347e+38],\n",
       " [-3.51867676e-02,  7.01293945e-02,  2.89764404e-02 ... -3.40282347e+38, -3.40282347e+38, -3.40282347e+38],\n",
       " ...\n",
       " [-1.82189941e-02,  4.60510254e-02,  3.79333496e-02 ... -1.85203552e-03, -3.40282347e+38, -3.40282347e+38],\n",
       " [ 1.98974609e-02, -6.01196289e-02,  3.48510742e-02 ...  2.45208740e-02, -8.94165039e-03, -3.40282347e+38],\n",
       " [ 6.25610352e-02, -3.41796875e-02,  3.34167480e-02 ...  4.76989746e-02, -7.72476196e-03,  1.26876831e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f61883-a535-4135-851c-c41e9c227e18",
   "metadata": {},
   "source": [
    "![](https://jalammar.github.io/images/gpt2/transformer-attention-masked-scores-softmax.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9cdaae-ac5a-4bc0-9e59-403d176c0d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 10, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = softmax(attn_weights, axis=-1)\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5771f68c-8b35-4b1a-83d1-287b2ce7a47e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[10, 10], dtype=Float32, value=\n",
       "[[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 5.01258850e-01,  4.98741180e-01,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 3.14729840e-01,  3.49684328e-01,  3.35585862e-01 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       " ...\n",
       " [ 1.20966740e-01,  1.28996551e-01,  1.27953634e-01 ...  1.22962892e-01,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 1.13199592e-01,  1.04494609e-01,  1.14905059e-01 ...  1.13724172e-01,  1.09981641e-01,  0.00000000e+00],\n",
       " [ 1.04792789e-01,  9.51299891e-02,  1.01782754e-01 ...  1.03246868e-01,  9.76802260e-02,  9.96946022e-02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a376e6b-0cd8-434a-aa5b-c647251200fa",
   "metadata": {},
   "source": [
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-multihead-sum-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba1e0ff-5627-4b70-8911-4ffa7383e29d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 10, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output = ops.matmul(attn_weights, value)\n",
    "\n",
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952ef91-b1e1-4d5b-9b42-a29f56f8f430",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 3.5- Merge attention heads\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-merge-heads-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80e44dd1-4013-4d01-b267-92463b296e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_heads(tensor, num_heads, attn_head_size):\n",
    "    \"\"\"\n",
    "    Merges attn_head_size dim and num_attn_heads dim into hidden_size\n",
    "    \"\"\"\n",
    "    tensor = ops.transpose(tensor, (0, 2, 1, 3))\n",
    "    new_shape = tensor.shape[:-2] + (num_heads * attn_head_size,)\n",
    "    return tensor.view(new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b35f8ee-70b4-4cb4-ad9b-d0b685482b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output = merge_heads(attn_output, num_heads, head_dim)\n",
    "\n",
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14b271-4432-44a0-b1f9-d2632ed2cd5b",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 4- Projecting\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-project-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff788df6-a6a7-4b43-9a76-95eaef4918c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_proj = Conv1D(embed_dim, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c7d4c1f-4ddc-4605-acba-f6e17cbfe2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 10, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output = c_proj(attn_output)\n",
    "attn_output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
